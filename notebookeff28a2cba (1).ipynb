{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11199196,"sourceType":"datasetVersion","datasetId":6992262}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\n\n# Проверка наличия GPU\nif torch.cuda.is_available():\n    print(\"GPU is available!\")\n    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n    print(f\"Current GPU: {torch.cuda.get_device_name(0)}\")\nelse:\n    print(\"GPU is not available.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T15:51:13.648977Z","iopub.execute_input":"2025-03-29T15:51:13.649308Z","iopub.status.idle":"2025-03-29T15:51:13.655497Z","shell.execute_reply.started":"2025-03-29T15:51:13.649280Z","shell.execute_reply":"2025-03-29T15:51:13.654788Z"}},"outputs":[{"name":"stdout","text":"GPU is available!\nNumber of GPUs: 2\nCurrent GPU: Tesla T4\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"!pip install transformers diffusers accelerate peft","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-29T16:46:06.153102Z","iopub.execute_input":"2025-03-29T16:46:06.153364Z","iopub.status.idle":"2025-03-29T16:46:10.706720Z","shell.execute_reply.started":"2025-03-29T16:46:06.153344Z","shell.execute_reply":"2025-03-29T16:46:10.705824Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (0.31.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\nRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (8.5.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (11.0.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.21.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!pip install langdetect\nimport os\nimport torch\nfrom diffusers import StableDiffusionPipeline, EulerAncestralDiscreteScheduler\nfrom transformers import MarianMTModel, MarianTokenizer\nfrom langdetect import detect\nfrom PIL import Image\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom accelerate import Accelerator\nfrom peft import LoraConfig, get_peft_model\nfrom tqdm.auto import tqdm\n\n# Очистка кэша GPU\ntorch.cuda.empty_cache()\n\n# Настройки устройства\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T16:46:10.708184Z","iopub.execute_input":"2025-03-29T16:46:10.708551Z","iopub.status.idle":"2025-03-29T16:46:37.308947Z","shell.execute_reply.started":"2025-03-29T16:46:10.708514Z","shell.execute_reply":"2025-03-29T16:46:37.307980Z"}},"outputs":[{"name":"stdout","text":"Collecting langdetect\n  Downloading langdetect-1.0.9.tar.gz (981 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.17.0)\nBuilding wheels for collected packages: langdetect\n  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=8fef49aa612ebfbb48efe23944ec884d4a2d6858935788345abb059dec466e5f\n  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\nSuccessfully built langdetect\nInstalling collected packages: langdetect\nSuccessfully installed langdetect-1.0.9\n","output_type":"stream"},{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f62f0a9bc6b4ecbb74ae87a8151d67d"}},"metadata":{}},{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Загружаем модель Stable Diffusion 2.1\npipe = StableDiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1-base\", torch_dtype=torch.float16)\npipe.to(device)\n\n# Используем другой сэмплер для лучшего качества\npipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T16:46:43.104704Z","iopub.execute_input":"2025-03-29T16:46:43.105131Z","iopub.status.idle":"2025-03-29T16:47:03.149553Z","shell.execute_reply.started":"2025-03-29T16:46:43.105094Z","shell.execute_reply":"2025-03-29T16:47:03.148521Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model_index.json:   0%|          | 0.00/543 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0ec9d4dc1d34782bd0e243c57b44ade"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47f096e32a6940e89137989bbd437a00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"230ceae837f9481abcc1f72b402466cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ebef4e4978641b58822b41a8a9afffb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e89778f11524e3db938a03ac40ce802"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/613 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5551ffd3a934182a9e06c1822d8e942"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/807 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2f13e428e544f5b853103b068acbac1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.36G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eacde76c64054970b6aff3ebc661e87e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/911 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d2ff9e4a1674449a1a5d6f197f28dfd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/553 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d7151c213d045bfad34d686962415af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/3.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ea4115aaf6843618abee60a3b2d885f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a794a3b919b24ec9a50defcf6af5ee42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler_config.json:   0%|          | 0.00/346 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b69b20e442a4485381a8724432a3c4c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d789d7b84355440f9f13de847a50f839"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9d61d9999214ba2bae090c251fba94c"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"def translate_ru_to_en(text):\n    model_name = \"Helsinki-NLP/opus-mt-ru-en\"\n    tokenizer = MarianTokenizer.from_pretrained(model_name)\n    model = MarianMTModel.from_pretrained(model_name).to(device)  # Переносим модель на GPU\n\n    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n    translated = model.generate(**inputs)\n    return tokenizer.decode(translated[0], skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T16:46:37.317126Z","iopub.execute_input":"2025-03-29T16:46:37.317474Z","iopub.status.idle":"2025-03-29T16:46:37.331105Z","shell.execute_reply.started":"2025-03-29T16:46:37.317443Z","shell.execute_reply":"2025-03-29T16:46:37.330140Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, image_dir, transform=None):\n        self.image_paths = [os.path.join(image_dir, fname) for fname in os.listdir(image_dir) if fname.endswith(('jpg', 'png', 'jpeg'))]\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path).convert(\"RGB\")  # Преобразуем в формат RGB\n        if self.transform:\n            image = self.transform(image)\n        return {'image': image}\n\n# Функция подготовки изображений для дообучения\ndef prepare_images(image_dir):\n    transform = transforms.Compose([\n        transforms.Resize((512, 512)),  # Изменяем размер до 512x512\n        transforms.ToTensor()          # Преобразуем в тензор\n    ])\n    dataset = ImageDataset(image_dir, transform=transform)\n    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n    return dataloader\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T16:49:20.746070Z","iopub.execute_input":"2025-03-29T16:49:20.746385Z","iopub.status.idle":"2025-03-29T16:49:20.752908Z","shell.execute_reply.started":"2025-03-29T16:49:20.746361Z","shell.execute_reply":"2025-03-29T16:49:20.751832Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from langdetect import detect\n\ndef process_prompt(user_input):\n    try:\n        lang = detect(user_input)\n    except:\n        lang = \"unknown\"\n\n    if lang == \"ru\":\n        translated_text = translate_ru_to_en(user_input)\n        print(f\"🔄 Переведено: {translated_text}\")\n        return translated_text\n    else:\n        print(f\"✅ Оставлено без изменений: {user_input}\")\n        return user_input","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T16:49:17.033664Z","iopub.execute_input":"2025-03-29T16:49:17.034090Z","iopub.status.idle":"2025-03-29T16:49:17.038908Z","shell.execute_reply.started":"2025-03-29T16:49:17.034060Z","shell.execute_reply":"2025-03-29T16:49:17.038004Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def fine_tune_lora(pipe, train_dataloader, prompt, num_epochs=3, lr=1e-4, output_dir=\"lora_weights\"):\n    print(\"🔧 Начало дообучения с LoRA...\")\n\n    # Настройка LoRA\n    lora_config = LoraConfig(\n        r=16,\n        lora_alpha=32,\n        target_modules=[\"to_k\", \"to_q\", \"to_v\", \"to_out.0\"],\n        lora_dropout=0.05,\n        bias=\"none\"\n    )\n\n    pipe.unet = get_peft_model(pipe.unet, lora_config)\n    pipe.unet.print_trainable_parameters()\n\n    optimizer = torch.optim.AdamW(pipe.unet.parameters(), lr=lr)\n    scaler = GradScaler()\n    accelerator = Accelerator()\n    pipe.unet, optimizer, train_dataloader = accelerator.prepare(pipe.unet, optimizer, train_dataloader)\n\n    for epoch in range(num_epochs):\n        pipe.unet.train()\n        progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n        for batch in progress_bar:\n            optimizer.zero_grad()\n\n            noise = torch.randn_like(batch['image']).to(device)\n            timesteps = torch.randint(0, 1000, (batch['image'].shape[0],), device=device).long()\n\n            text_input = [prompt] * batch['image'].shape[0]\n            text_input = pipe.tokenizer(text_input, padding=\"max_length\", truncation=True, max_length=77, return_tensors=\"pt\").input_ids.to(device)\n            encoder_hidden_states = pipe.text_encoder(text_input).last_hidden_state\n\n            noisy_images = pipe.scheduler.add_noise(batch['image'], noise, timesteps)\n\n            with autocast():\n                noise_pred = pipe.unet(noisy_images, timesteps, encoder_hidden_states=encoder_hidden_states).sample\n\n            loss = torch.nn.functional.mse_loss(noise_pred, noise)\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n\n            progress_bar.set_postfix(loss=loss.item())\n\n    os.makedirs(output_dir, exist_ok=True)\n    pipe.unet.save_pretrained(output_dir)\n    print(f\"✅ Дообучение завершено. Веса сохранены в '{output_dir}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T16:49:09.938094Z","iopub.execute_input":"2025-03-29T16:49:09.938377Z","iopub.status.idle":"2025-03-29T16:49:09.946328Z","shell.execute_reply.started":"2025-03-29T16:49:09.938355Z","shell.execute_reply":"2025-03-29T16:49:09.945590Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def generate_image(prompt, negative_prompt=\"low quality, blurry, poorly drawn, distorted, deformed, bad anatomy, bad proportions, watermark, text, nsfw\"):\n    image = pipe(prompt, negative_prompt=negative_prompt, guidance_scale=7.5).images[0]\n    image.save(\"generated_image.png\")\n    print(\"✅ Изображение сохранено как 'generated_image.png'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T16:29:56.902032Z","iopub.execute_input":"2025-03-29T16:29:56.902384Z","iopub.status.idle":"2025-03-29T16:29:56.906591Z","shell.execute_reply.started":"2025-03-29T16:29:56.902358Z","shell.execute_reply":"2025-03-29T16:29:56.905741Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Путь к папке с изображениями\n    image_dir = \"/kaggle/input/in-img\"  # Укажите путь к вашим изображениям\n    train_dataloader = prepare_images(image_dir)\n\n    # Промт для дообучения\n    prompt_for_finetuning = \"A photo of a girl named Anya\"\n\n    # Дообучение LoRA\n    lora_weights_dir = \"lora_weights\"\n    fine_tune_lora(pipe, train_dataloader, prompt_for_finetuning, num_epochs=3, lr=1e-4, output_dir=lora_weights_dir)\n\n    # Генерация изображения\n    user_prompt = \"Фотография девушки по имени Аня, на пляже с крабами, хорошеее качество\"\n    final_prompt = process_prompt(user_prompt)  # Перевод, если нужно\n    negative_prompt_default = \"low quality, blurry, poorly drawn, distorted, deformed, bad anatomy, bad proportions, watermark, text, nsfw\"\n    generate_image(final_prompt, negative_prompt_default)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T16:49:25.460687Z","iopub.execute_input":"2025-03-29T16:49:25.460998Z","iopub.status.idle":"2025-03-29T16:49:25.733420Z","shell.execute_reply.started":"2025-03-29T16:49:25.460972Z","shell.execute_reply":"2025-03-29T16:49:25.732221Z"}},"outputs":[{"name":"stdout","text":"🔧 Начало дообучения с LoRA...\ntrainable params: 3,319,808 || all params: 869,230,532 || trainable%: 0.3819\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-bdfc6b6d4675>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Дообучение LoRA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlora_weights_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"lora_weights\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mfine_tune_lora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt_for_finetuning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlora_weights_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Генерация изображения\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-3bfd27257002>\u001b[0m in \u001b[0;36mfine_tune_lora\u001b[0;34m(pipe, train_dataloader, prompt, num_epochs, lr, output_dir)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0maccelerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAccelerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'GradScaler' is not defined"],"ename":"NameError","evalue":"name 'GradScaler' is not defined","output_type":"error"}],"execution_count":16}]}